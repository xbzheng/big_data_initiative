{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Analyzing Sensor Data with Spark Steaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Ivan Zheng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: 10/01/2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example weather station data\n",
    "#\n",
    "# 1419408015\t0R1,Dn=059D,Dm=066D,Dx=080D,Sn=8.5M,Sm=9.5M,Sx=10.3M\n",
    "# 1419408016\t0R1,Dn=059D,Dm=065D,Dx=078D,Sn=8.5M,Sm=9.5M,Sx=10.3M\n",
    "# 1419408016\t0R2,Ta=13.9C,Ua=28.5P,Pa=889.9H\n",
    "# 1419408017\t0R1,Dn=059D,Dm=064D,Dx=075D,Sn=8.7M,Sm=9.6M,Sx=10.3M\n",
    "# 1419408018\t0R1,Dn=059D,Dm=064D,Dx=075D,Sn=8.9M,Sm=9.6M,Sx=10.3M\n",
    "# 1419408019\t0R1,Dn=059D,Dm=065D,Dx=075D,Sn=8.8M,Sm=9.5M,Sx=10.3M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line contains a timestamp and a set of measurements. Each measurement has an abbreviation, and for this exercise, we are interested in the average wind direction, which is Dm. The next cell lists the abbreviations used for each type of measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key for measurements:\n",
    "#\n",
    "# Sn      Wind speed minimum m/s, km/h, mph, knots #,M, K, S, N\n",
    "# Sm      Wind speed average m/s, km/h, mph, knots #,M, K, S, N\n",
    "# Sx      Wind speed maximum m/s, km/h, mph, knots #,M, K, S, N\n",
    "# Dn      Wind direction minimum deg #, D\n",
    "# Dm      Wind direction average deg #, D\n",
    "# Dx      Wind direction maximum deg #, D\n",
    "# Pa      Air pressure hPa, Pa, bar, mmHg, inHg #, H, P, B, M, I\n",
    "# Ta      Air temperature °C, °F #, C, F\n",
    "# Tp      Internal temperature °C, °F #, C, F\n",
    "# Ua      Relative humidity %RH #, P\n",
    "# Rc      Rain accumulation mm, in #, M, I\n",
    "# Rd      Rain duration s #, S\n",
    "# Ri      Rain intensity mm/h, in/h #, M, I\n",
    "# Rp      Rain peak intensity mm/h, in/h #, M, I\n",
    "# Hc      Hail accumulation hits/cm2, hits/in2, hits #, M, I, H\n",
    "# Hd      Hail duration s #, S\n",
    "# Hi      Hail intensity hits/cm2h, hits/in2h, hits/ h #, M, I, H\n",
    "# Hp      Hail peak intensity hits/cm2h, hits/in2h, hits/ h #, M, I, H\n",
    "# Th      Heating temperature °C, °F #, C, F\n",
    "# Vh      Heating voltage V #, N, V, W, F2\n",
    "# Vs      Supply voltage V V\n",
    "# Vr      3.5 V ref. voltage V V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third cell defines a function that parses each line and returns the average wind direction (Dm). Run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse a line of weather station data, returning the average wind direction measurement \n",
    "#\n",
    "import re\n",
    "def parse(line):\n",
    "    match = re.search(\"Dm=(\\d+)\", line)\n",
    "    if match:\n",
    "        val = match.group(1)\n",
    "        return [int(val)]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Import and create streaming context. Next, we will import and create a new instance of Spark's StreamingContext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "ssc = StreamingContext(sc,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the SparkContext, the StreamingContext provides an interface to Spark's streaming capabilities. The argument sc is the SparkContext, and 1 specifies a batch interval of one second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Create DStream of weather data. Let's open a connection to the streaming weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"rtd.hpwren.ucsd.edu\", 12028)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This create a new variable, lines, to be a Spark DStream that streams the lines of output from the weather station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Read measurement. Next, let's read the average wind speed from each line and store it in a new DStream vals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vals = lines.flatMap(parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line uses flatMap() to iterate over the lines DStream, and calls the parse() function we defined above to get the average wind speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Create sliding window of data. We can create a sliding window over the measurements by calling the window() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = vals.window(10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This create a new DStream called window that combines the ten seconds worth of data and moves by five seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. Define and call analysis function. We would like to find the minimum and maximum values in our window. Let's define a function that prints these values for an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stats(rdd):\n",
    "    print(rdd.collect())\n",
    "    if rdd.count() > 0:\n",
    "        print(\"max = {}, min = {}\".format(rd.max(), rdd.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function first prints the entire contents of the RDD by calling the collect() method. This is done to demonstrate the sliding window and would not be practical if the RDD was containing a large amount of data. Next, we check if the size of the RDD is greater than zero before printing the maximum and minimum values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next, we call the stats() function for each RDD in our sliding window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window.foreachRDD(lambda rdd: stats(rdd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This line calls the stats() function defined above for each RDD in the DStream window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Start the stream processing. We call start() on the StreamingContext to begin the processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sliding window contains ten seconds worth of data and slides every five seconds. In the beginning, the number of values in the windows are increasing as the data accumulates, and after Window 3, the size stays (approximately) the same. Since the window slides half as often as the size of the window, the second half of a window becomes the first half of the next window. For example, the second half of Window 5 is 310, 321, 323, 325, 326, which becomes the first half of Window 6.\n",
    "\n",
    "When we are done, call stop() on the StreamingContext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
