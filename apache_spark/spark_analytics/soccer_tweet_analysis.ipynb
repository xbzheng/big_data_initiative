{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Title: identifying most popular country "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Ivan Zheng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: 10/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import and create a new SQLContext \n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Transforming the Country Data to pyspark SQL formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the country CSV file into an RDD.\n",
    "country_lines = sc.textFile('data/country-list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan, AFG',\n",
       " 'Albania, ALB',\n",
       " 'Algeria, ALG',\n",
       " 'American Samoa, ASA',\n",
       " 'Andorra, AND']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_lines.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert each line into a pair of words\n",
    "country_words = country_lines.map(lambda line : line.split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Afghanistan', 'AFG'],\n",
       " ['Albania', 'ALB'],\n",
       " ['Algeria', 'ALG'],\n",
       " ['American Samoa', 'ASA'],\n",
       " ['Andorra', 'AND']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert each pair of words into a tuple\n",
    "country_tuples = country_words.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Afghanistan', 'AFG'),\n",
       " ('Albania', 'ALB'),\n",
       " ('Algeria', 'ALG'),\n",
       " ('American Samoa', 'ASA'),\n",
       " ('Andorra', 'AND')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_tuples.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', code='AFG'),\n",
       " Row(country='Albania', code='ALB'),\n",
       " Row(country='Algeria', code='ALG')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame, look at schema and contents\n",
    "countryDF = sqlContext.createDataFrame(country_tuples, [\"country\", \"code\"])\n",
    "countryDF.printSchema()\n",
    "countryDF.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Transformed the Country Date to pyspark SQL formate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculating the most popular country in tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read tweets CSV file into RDD of lines\n",
    "tweet_lines = sc.textFile('data/tweet_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet_text',\n",
       " 'RT @ochocinco: I beat them all for 10 straight hours #FIFA16KING  https://t.co/BFnV6jfkBL',\n",
       " 'RT @NiallOfficial: @Louis_Tomlinson @socceraid when I retired from playing because of my knee . I went and did my uefa A badges in Dublin']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_lines.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13995"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_lines.count() #before cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the data: some tweets are empty. Remove the empty tweets using filter() \n",
    "tweet_lines = tweet_lines.filter(lambda x: x is not ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13989"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_lines.count() #before removing null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform WordCount on the cleaned tweet texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_words = tweet_lines.flatMap(lambda line : line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tuples = tweet_words.map(lambda word : (word, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_counts = tweet_tuples.reduceByKey(lambda a, b: (a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tweet_text', 1), ('beat', 51), ('them', 70), ('10', 115), ('hours', 59)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- counts: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='tweet_text', counts=1),\n",
       " Row(country='beat', counts=51),\n",
       " Row(country='them', counts=70)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame of tweet word counts\n",
    "tweetDF = sqlContext.createDataFrame(tweet_counts, [\"country\", \"counts\"])\n",
    "tweetDF.printSchema()\n",
    "tweetDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join the country and tweet data frames (on the appropriate column)\n",
    "countryDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             country|counts|\n",
      "+--------------------+------+\n",
      "|          tweet_text|     1|\n",
      "|                beat|    51|\n",
      "|                them|    70|\n",
      "|                  10|   115|\n",
      "|               hours|    59|\n",
      "|         #FIFA16KING|    27|\n",
      "|                    |  3884|\n",
      "|https://t.co/BFnV...|    27|\n",
      "|    @Louis_Tomlinson|     3|\n",
      "|          @socceraid|     3|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweetDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+\n",
      "|            country|code|\n",
      "+-------------------+----+\n",
      "|        Afghanistan| AFG|\n",
      "|            Albania| ALB|\n",
      "|            Algeria| ALG|\n",
      "|     American Samoa| ASA|\n",
      "|            Andorra| AND|\n",
      "|             Angola| ANG|\n",
      "|           Anguilla| AIA|\n",
      "|Antigua and Barbuda| ATG|\n",
      "|          Argentina| ARG|\n",
      "|            Armenia| ARM|\n",
      "+-------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countryDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergeDF = countryDF.join(tweetDF, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|country|code|counts|\n",
      "+-------+----+------+\n",
      "|   Chad| CHA|     9|\n",
      "| Russia| RUS|    15|\n",
      "|   Iraq| IRQ|     6|\n",
      "|Germany| GER|    20|\n",
      "| Jordan| JOR|     6|\n",
      "+-------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergeDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of distinct countries mentioned\n",
    "mergeDF.filter(mergeDF[\"counts\"] > 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(counts)|\n",
      "+-----------+\n",
      "|        397|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Number of countries mentioned in tweets.\n",
    "from pyspark.sql.functions import sum\n",
    "mergeDF.select(sum('counts')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+------+\n",
      "| country|code|counts|\n",
      "+--------+----+------+\n",
      "|  Norway| NOR|    52|\n",
      "| Nigeria| NGA|    49|\n",
      "|  France| FRA|    42|\n",
      "|Slovakia| SVK|    30|\n",
      "| England| ENG|    25|\n",
      "+--------+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 1: top three countries and their counts.\n",
    "from pyspark.sql.functions import desc\n",
    "mergeDF.sort(mergeDF.counts.desc()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|country|code|counts|\n",
      "+-------+----+------+\n",
      "|  Wales| WAL|    19|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 2: counts for Wales, Iceland, and Japan.\n",
    "mergeDF.filter(mergeDF[\"country\"] == 'Wales').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|country|code|counts|\n",
      "+-------+----+------+\n",
      "|  Kenya| KEN|     3|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergeDF.filter(mergeDF[\"country\"] == 'Kenya').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------+\n",
      "|    country|code|counts|\n",
      "+-----------+----+------+\n",
      "|Netherlands| NED|    13|\n",
      "+-----------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergeDF.filter(mergeDF[\"country\"] == 'Netherlands').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|country|code|counts|\n",
      "+-------+----+------+\n",
      "|Iceland| ISL|     2|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergeDF.filter(mergeDF[\"country\"] == 'Iceland').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|country|code|counts|\n",
      "+-------+----+------+\n",
      "|  Japan| JPN|     5|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergeDF.filter(mergeDF[\"country\"] == 'Japan').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary, a short spark exercise using PySpark SQL and generate output using MonogDB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
